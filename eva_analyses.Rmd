---
title: "Eva Analyses"
author: "Eva Wu"
date: "`r Sys.Date()`"
output: github_document
---

```{r setup, include = FALSE}
library(tidyverse)
library(ggpubr)
library(corrplot)
library(rstatix)
library(emmeans)

data <- read_csv("all.csv")
desc <- read_csv("descriptives.csv")
```

Very helpful [link](https://www.datanovia.com/en/lessons/mixed-anova-in-r/)!

## Summary Statistics

```{r descr}
attach(data)
# descriptives
summary(data)

# marginal means 
# instrument
desc %>%
  group_by(instrument) %>%
  summarize(mean_pct_inst = mean(mean_pct),
            sd_pct_inst = sd(mean_pct), # is this the right way to calculate sd? or should this be done in previous steps
            mean_rtg_inst = mean(mean_rtg),
            sd_rtg_inst = sd(mean_rtg))

# tuning step
desc %>%
  group_by(tuning_step) %>%
  summarize(mean_pct_tune = mean(mean_pct), 
            sd_pct_tune = sd(mean_pct),
            mean_rtg_tune = mean(mean_rtg),
            sd_rtg_tune = sd(mean_rtg))

# key
desc %>%
  group_by(chord) %>%
  summarize(mean_pct_key = mean(mean_pct), 
            sd_pct_key = sd(mean_pct),
            mean_rtg_key = mean(mean_rtg),
            sd_rtg_key = sd(mean_rtg))

data %>%
  group_by(instrument, tuning_step, chord) %>%
  get_summary_stats(pct_maj, explicit_rtg, type = "mean_sd")
```

## Visualization

```{r graph}
data %>% 
  ggplot(aes(tuning_step, pct_maj, color = instrument)) +
  geom_smooth(se = FALSE) +
  facet_wrap(~chord) +
  labs(title = "Proportion of major chord categorization across different instruments and tuning steps",
       subtitle = "compared between the key of B and C",
       x = "Tuning step (+0c ~ +100c)", y = "Proportion of major categorization") +
  theme_bw()

data %>% 
  ggplot(aes(tuning_step, pct_maj, color = chord)) +
  geom_smooth(se = FALSE) +
  facet_wrap(~instrument) +
  labs(title = "Proportion of major chord categorization across different keys and tuning steps",
       x = "Tuning step (+0c ~ +100c)", y = "Proportion of major categorization") +
  theme_bw()

data %>% 
  ggplot(aes(reorder(instrument, explicit_rtg), explicit_rtg, fill = instrument)) +
  geom_col() +
  facet_wrap(~chord) +
  labs(title = "Mean explicit valence rating across different instruments",
       subtitle = "compared between the key of B and C",
       x = "Instrument", y = "Mean explicit valence rating") +
  theme_bw()
```

## Check assumptions

### Outliers

```{r outliers}
# for cat
data %>%
  group_by(qualtrics_id) %>%
  summarize(mean_pct = mean(pct_maj)) %>%
  ggplot(aes(mean_pct)) +
  geom_histogram(color = "white")

data %>%
  group_by(qualtrics_id) %>%
  summarize(mean_pct = mean(pct_maj)) %>%
  identify_outliers(mean_pct)

# for rtg
data %>%
  group_by(qualtrics_id) %>%
  summarize(mean_rtg = mean(explicit_rtg)) %>%
  ggplot(aes(mean_rtg)) +
  geom_histogram(color = "white")

data %>%
  group_by(qualtrics_id) %>%
  summarize(mean_rtg = mean(explicit_rtg)) %>%
  identify_outliers(mean_rtg)

# examine outliers
data %>%
  filter(qualtrics_id == 1588756489 | qualtrics_id == 6323213291 | qualtrics_id == 6444402078) %>%
  select(qualtrics_id, instrument, explicit_rtg) %>%
  unique()

# ignore b/c not extreme
```

### Normality

```{r}
norm_model <- lm(pct_maj ~ instrument*tuning_step*chord, data = data)
# Create a QQ plot of residuals
ggqqplot(residuals(norm_model))
# Compute Shapiro-Wilk test of normality
shapiro_test(residuals(norm_model))

data %>%
  group_by(instrument, tuning_step, chord) %>%
  shapiro_test(pct_maj)

ggqqplot(data, "pct_maj", ggtheme = theme_bw()) +
  facet_grid(tuning_step ~ instrument, labeller = "label_both")
```

### Homogeneity of variance

```{r}
data %>% levene_test(pct_maj ~ instrument*factor(tuning_step)*chord)
```

No need to transform for assumption violations b/c ANOVA is robust for these issues. Just report a Greenhouse-Geisser correction.

multiply the Greenhouse–Geisser estimate of epsilon to the degrees of freedom used to 
calculate the F critical value

The assumption of sphericity will be automatically checked during the computation of the ANOVA test using the R function anova_test() [rstatix package]. The Mauchly’s test is internally used to assess the sphericity assumption.

By using the function get_anova_table() [rstatix] to extract the ANOVA table, the Greenhouse-Geisser sphericity correction is automatically applied to factors violating the sphericity assumption.

## ANOVA

```{r}
res.aov <- anova_test(data = data, dv = pct_maj, wid = qualtrics_id,
  within = c(instrument, tuning_step), between = chord)
get_anova_table(res.aov) # sphericity violated but corrected w/ GG

# A significant two-way interaction can be followed up by a simple main effect analysis, 
# which can be followed up by simple pairwise comparisons if significant.
```

## Post-hoc tests

```{r post-hoc}
inst.effect <- data %>%
  group_by(tuning_step, chord) %>%
  anova_test(dv = pct_maj, wid = qualtrics_id, within = instrument)

get_anova_table(inst.effect)

tune.effect <- data %>%
  group_by(instrument, chord) %>%
  anova_test(dv = pct_maj, wid = qualtrics_id, within = tuning_step)

get_anova_table(tune.effect)

chord.effect <- data %>%
  group_by(instrument, tuning_step) %>%
  anova_test(dv = pct_maj, wid = qualtrics_id, between = chord)

get_anova_table(chord.effect)

anova_test(data = data %>% filter(chord == "B"), dv = pct_maj, wid = qualtrics_id,
  within = c(instrument, tuning_step))

anova_test(data = data %>% filter(tuning_step == 1), dv = pct_maj, wid = qualtrics_id,
  within = instrument, between = chord)

anova_test(data = data %>% filter(chord == "C"), dv = pct_maj, wid = qualtrics_id,
  within = c(instrument, tuning_step))

# Group the data by instrument and fit simple two-way interaction 
post_model <- lm(pct_maj ~ instrument*tuning_step*chord, data = data)
data %>%
  group_by(instrument) %>%
  anova_test(pct_maj ~ tuning_step*chord, error = post_model)

# p needs to < .01 in order to qualify for Bonferroni-corrected significant

# pairwise comparisons of the effect of instruments
data %>%
  group_by(tuning_step, chord) %>%
  emmeans_test(pct_maj ~ instrument, p.adjust.method = "bonferroni") %>%
  select(-df, -p) # Remove details

# pairwise comparisons of the effect of tuning_step on pct_maj b/w keys
data %>%
  group_by(chord) %>%
  emmeans_test(pct_maj ~ tuning_step, p.adjust.method = "bonferroni") %>%
  select(-df, -p) # Remove details
```

## Correlations b/w DV & other predictors

```{r corr}
cor.test(data$pct_maj, data$Inst)
cor.test(data$pct_maj, data$Inst_yr)
cor.test(data$pct_maj, data$music_exp)
cor.test(data$pct_maj, data$Read) #*
cor.test(data$pct_maj, data$headphone)
cor.test(data$pct_maj, data$Age)
cor.test(data$pct_maj, data$explicit_rtg) #***
```

Ability to read music and explicit valence rating were significantly correlated with percent of major categorization

```{r corrplot}
corrplot(cor(data %>%
  select(pct_maj, explicit_rtg, practice_score, Age, 16:21), use = "complete.obs"), method = "color")
# why NA?
```

## Logistic regression (wrong, should use selected_major as DV)

1) Percent major ~ instrument & tuning step

```{r log-reg}
#glm.fit <- glm(pct_maj ~ instrument + tuning_step, family = binomial) 
# family = binomial tells r to run logistic regression
#summary(glm.fit)
```

2) Percent major ~ mean explicit rating of each instrument & tuning step

```{r log-reg2}
#glm.fit2 <- glm(pct_maj ~ mean_rtg + tuning_step, family = binomial) 
# family= binomial tells r to run logistic regression
#summary(glm.fit2)
```

Linear regression

```{r lm-fit-both}
#lm.fit2 <- lm(pct_maj ~ tuning_step, data = cat)
#lm.fit <- lm(pct_maj ~ instrument + tuning_step, data = cat) 
#summary(lm.fit)
```

ANOVA exploring 1) whether adding instrument as a predictor significantly improves model, 
and 2) whether adding both predictors is significantly better than null model

```{r lm-anova}
#anova(lm.fit, lm.fit2) # adding instrument significantly improves model
#anova(lm.fit) # adding both predictors significantly better than null model
```
